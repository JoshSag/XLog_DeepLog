{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.gmtime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools, collections\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from _code import DeepLogModel\n",
    "from _code import generator\n",
    "from _code import seed\n",
    "from _code import trie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameters\n",
    "_seed={0[seed]}\n",
    "subdir = \"{0[subdir]}\"\n",
    "vocabulary_size = {0[vocabulary_size]}\n",
    "num_patterns = {0[num_patterns]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed.seed(_seed)\n",
    "subdir = subdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = vocabulary_size\n",
    "num_patterns = num_patterns\n",
    "vocabulary = generator.make_vocabulary(vocabulary_size=vocabulary_size)\n",
    "patterns = generator.generate_patterns(num_patterns=num_patterns, vocabulary=vocabulary, min_pattern_size=3, max_pattern_size=7)\n",
    "trie_g = trie.calc_g_value(patterns)\n",
    "trie_h = trie.calc_h_value(patterns)\n",
    "print(\"trie-g:\", trie_g)\n",
    "print(\"trie-h:\", trie_h)\n",
    "text_train, marks_train = generator.generate_text(patterns, text_size=50000, anomaly_ratio=0.00, vocabulary=vocabulary) \n",
    "tests = generator.generate_tests(patterns, vocabulary, n=1000, text_size = 4, anomaly_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "\n",
    "def write_inputs(subdir, vocabulary_size, vocabulary, patterns, text_train, marks_train, tests):\n",
    "    dir_= os.path.join(\"..\\\\inputs\", subdir)\n",
    "    os.makedirs(dir_, exist_ok=True)\n",
    "    j1={\n",
    "        \"vocabulary_size\" : vocabulary_size,\n",
    "        \"vocabulary\" : vocabulary,\n",
    "        \"workflows\" : patterns\n",
    "    }\n",
    "    json.dump(j1, open(os.path.join(dir_, \"v-wf.json\"), \"w\"))\n",
    "\n",
    "    j2 = {\"text_train\" : text_train, \"marks_train\" : marks_train}\n",
    "    json.dump(j2, open(os.path.join(dir_, \"train.json\"), \"w\"))\n",
    "\n",
    "    j3 = {\"tests\" : tests}\n",
    "    json.dump(j3, open(os.path.join(dir_, \"tests.json\"), \"w\"))\n",
    "\n",
    "def read_inputs(subdir):\n",
    "    dir_ = os.path.join(\"..\\\\inputs\", subdir)\n",
    "    j1 = json.load(open(os.path.join(dir_, \"v-wf.json\")))\n",
    "    j2 = json.load(open(os.path.join(dir_, \"train.json\")))\n",
    "    j3 = json.load(open(os.path.join(dir_, \"tests.json\")))\n",
    "    \n",
    "    vocabulary_size = j1[\"vocabulary_size\"]\n",
    "    vocabulary = j1[\"vocabulary\"]\n",
    "    patterns = j1[\"workflows\"]\n",
    "    patterns = [tuple(p) for p in patterns]\n",
    "    \n",
    "    text_train = j2[\"text_train\"]\n",
    "    marks_train = j2[\"marks_train\"]\n",
    "    \n",
    "    tests_str_keys = j3[\"tests\"]\n",
    "    tests = dict()\n",
    "    for k,v in tests_str_keys.items():\n",
    "        tests[int(k)] = tuple(v)\n",
    "    \n",
    "    \n",
    "    return vocabulary_size, vocabulary, patterns, text_train, marks_train, tests\n",
    "\n",
    "write_inputs(subdir, vocabulary_size, vocabulary, patterns, text_train, marks_train, tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_vocabulary_size, ret_vocabulary, ret_patterns, ret_text_train, ret_marks_train, ret_tests = read_inputs(subdir)\n",
    "\n",
    "assert ret_vocabulary_size == vocabulary_size\n",
    "assert ret_vocabulary == vocabulary\n",
    "assert ret_patterns == patterns\n",
    "assert ret_text_train == text_train\n",
    "assert ret_marks_train == marks_train\n",
    "assert ret_tests == tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_log_model = DeepLogModel.DeepLogModel(h=trie_h+1, n=vocabulary_size, vocabulary=vocabulary)\n",
    "deep_log_model.build(num_lstm_layers=2, lstm_size=64)\n",
    "deep_log_model.fit(text_train,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = time.time()\n",
    "entries = list()\n",
    "for k, (text_test, text_marks, anomaly) in tests.items():\n",
    "    for g in range(0, vocabulary_size+1):\n",
    "        res = deep_log_model.monitor_session(text_test, text_marks, g=g)\n",
    "        entry = (k,g,res)\n",
    "        entries.append(entry)\n",
    "e = time.time()\n",
    "print(\"time:\", round(e-b,3), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(entries, columns = [\"i\",\"g\",\"status\"])\n",
    "ddf = df.pivot_table(index=\"i\", columns = \"g\", values = \"status\", aggfunc = \"sum\")\n",
    "def calc(s):\n",
    "    c = dict(collections.Counter(s))\n",
    "    TP = c.get(\"TP\", 0)\n",
    "    TN = c.get(\"TN\", 0)\n",
    "    FP = c.get(\"FP\", 0)\n",
    "    FN = c.get(\"FN\", 0)\n",
    "    eps = 1e-9\n",
    "    \n",
    "    prec = TP / (TP + FP + eps)\n",
    "    rec = TP / (TP + FN + eps)\n",
    "    acc = (TP + TN) / (TP + TN + FP + FN + eps)\n",
    "    f1 = 2*(prec*rec)/(prec+rec+eps)\n",
    "    \n",
    "    return {\"prec\" : prec, \"rec\" : rec, \"acc\" : acc, \"f1\" : f1, \"TP\" : TP, \"TN\" : TN, \"FP\" : FP, \"FN\" : FN}\n",
    "    \n",
    "e=ddf.apply(calc, axis=0)\n",
    "e1=pd.DataFrame(list(e.values))\n",
    "\n",
    "print(\"measure results for each g-value\")\n",
    "e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_outputs(subdir, df, ddf, e1):\n",
    "    df.to_csv(os.path.join(\"..\\inputs\", subdir, \"DL-results.csv\"))\n",
    "    ddf.to_csv(os.path.join(\"..\\inputs\", subdir, \"DL-resuls_pivot.csv\"))\n",
    "    e1.to_csv(os.path.join(\"..\\inputs\", subdir, \"DL-resutls_metrics.csv\"))\n",
    "\n",
    "write_outputs(subdir, df, ddf, e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(e1.loc[[e1[\"acc\"].argmax()]])\n",
    "display(e1.loc[[e1[\"f1\"].argmax()]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
