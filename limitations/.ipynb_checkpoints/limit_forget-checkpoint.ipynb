{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.gmtime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "from _code import DeepLogModel\n",
    "from _code import generator\n",
    "from _code import trie\n",
    "from _code import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 20\n",
    "num_patterns = 20\n",
    "vocabulary = generator.make_vocabulary(vocabulary_size=vocabulary_size)\n",
    "patterns = generator.generate_patterns(num_patterns=num_patterns, vocabulary=vocabulary, min_pattern_size=3, max_pattern_size=7)\n",
    "\n",
    "trie_g = trie.calc_g_value(patterns)\n",
    "trie_h = trie.calc_h_value(patterns)\n",
    "print(\"trie-g:\", trie_g)\n",
    "print(\"trie-h:\", trie_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, marks_train = generator.generate_text(patterns, text_size=50000, anomaly_ratio=0.00, vocabulary=vocabulary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_log_model = DeepLogModel.DeepLogModel(h=trie_h+1, n=vocabulary_size, vocabulary=vocabulary)\n",
    "deep_log_model.build(num_lstm_layers=2, lstm_size=64)\n",
    "deep_log_model.fit(text_train,epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## README\n",
    "1. After the training we evaluates the network over tests, to see the current best performnace.\n",
    "2. We use feedback to train the network for a new workflow with different contexts\n",
    "3. We evaluate the updated network again over the previous tests.\n",
    "4. The decline in performance results is actually the degree of forgetfulness of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_legit = generator.generate_tests(patterns, vocabulary, n=1000, text_size = 4, anomaly_ratio=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = time.time()\n",
    "entries = list()\n",
    "for k, (text_test, text_marks, anomaly) in tests_legit.items():\n",
    "    for g in range(0, vocabulary_size+1):\n",
    "#     for g in [trie_g-2, trie_g-1,trie_g,trie_g+1,trie_g+2]:\n",
    "        res = deep_log_model.monitor_session(text_test, text_marks, g=g)\n",
    "        entry = (k,g,res)\n",
    "        entries.append(entry)\n",
    "e = time.time()\n",
    "print(\"time:\", round(e-b,3), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(entries, columns = [\"i\",\"g\",\"status\"])\n",
    "ddf1 = df1.pivot_table(index=\"i\", columns = \"g\", values = \"status\", aggfunc = \"sum\")\n",
    "def calc(s):\n",
    "    c = dict(collections.Counter(s))\n",
    "    TP = c.get(\"TP\", 0)\n",
    "    TN = c.get(\"TN\", 0)\n",
    "    FP = c.get(\"FP\", 0)\n",
    "    FN = c.get(\"FN\", 0)\n",
    "    eps = 1e-9\n",
    "    \n",
    "    prec = TP / (TP + FP + eps)\n",
    "    rec = TP / (TP + FN + eps)\n",
    "    acc = (TP + TN) / (TP + TN + FP + FN + eps)\n",
    "    f1 = 2*(prec*rec)/(prec+rec+eps)\n",
    "    \n",
    "    return {\"prec\" : prec, \"rec\" : rec, \"acc\" : acc, \"f1\" : f1, \"TP\" : TP, \"TN\" : TN, \"FP\" : FP, \"FN\" : FN}\n",
    "    \n",
    "e1=ddf1.apply(calc, axis=0)\n",
    "e1=pd.DataFrame(list(e1.values))\n",
    "\n",
    "print(\"measure results for each g-value\")\n",
    "e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_g = e1[\"f1\"].argmax()\n",
    "print(\"best-g\", best_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_workflows = generator.generate_patterns(num_patterns=1, vocabulary=vocabulary, min_pattern_size=3, max_pattern_size=7)\n",
    "new_workflow = new_workflows[0]\n",
    "assert new_workflow not in patterns\n",
    "\n",
    "trie_g2 = trie.calc_g_value(patterns + [new_workflow])\n",
    "print(\"trie-g2\", trie_g2)\n",
    "if trie_g2 > best_g:\n",
    "    best_g = trie_g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_marks = [1]*len(new_workflow)\n",
    "new = dict()\n",
    "for i in range(20): # this new workflow will typically appear in many different contexts\n",
    "    before_text, before_marks = generator.generate_text(patterns, text_size=2, anomaly_ratio=0.00, vocabulary=vocabulary)\n",
    "    after_text, after_marks = generator.generate_text(patterns, text_size=1, anomaly_ratio=0.00, vocabulary=vocabulary)\n",
    "    new_text = before_text + list(new_workflow) + after_text\n",
    "    new_marks = before_text + list(new_workflow) + after_text\n",
    "    new[i] = (new_text, new_marks)\n",
    "\n",
    "B = list()\n",
    "for i, (new_text, new_marks) in new.items():\n",
    "    B.append(deep_log_model.monitor_session(new_text, new_marks, g=best_g))\n",
    "print(\"before\", B)\n",
    "    \n",
    "A1 = list()\n",
    "for i, (new_text, new_marks) in new.items():\n",
    "    deep_log_model.train_feedback(new_text, new_marks, g = best_g)\n",
    "    A1.append(deep_log_model.monitor_session(new_text, new_marks, g=best_g))\n",
    "print(\"after\", A1)\n",
    "\n",
    "A = list()\n",
    "for i, (new_text, new_marks) in new.items():\n",
    "    A.append(deep_log_model.monitor_session(new_text, new_marks, g=best_g))\n",
    "\n",
    "print(\"after all\", A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = list()\n",
    "for k, (text_test, text_marks, anomaly) in tests_legit.items():\n",
    "    for g in range(0, vocabulary_size+1):\n",
    "#     for g in [best_g-2, best_g-1, best_g, best_g+1,best_g+2]:\n",
    "        res = deep_log_model.monitor_session(text_test, text_marks, g=g)\n",
    "        entry = (k,g,res)\n",
    "        entries.append(entry)\n",
    "# entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(entries, columns = [\"i\",\"g\",\"status\"])\n",
    "ddf2 = df2.pivot_table(index=\"i\", columns = \"g\", values = \"status\", aggfunc = \"sum\")\n",
    "def calc(s):\n",
    "    c = dict(collections.Counter(s))\n",
    "    TP = c.get(\"TP\", 0)\n",
    "    TN = c.get(\"TN\", 0)\n",
    "    FP = c.get(\"FP\", 0)\n",
    "    FN = c.get(\"FN\", 0)\n",
    "    eps = 1e-9\n",
    "    \n",
    "    prec = TP / (TP + FP + eps)\n",
    "    rec = TP / (TP + FN + eps)\n",
    "    acc = (TP + TN) / (TP + TN + FP + FN + eps)\n",
    "    f1 = 2*(prec*rec)/(prec+rec+eps)\n",
    "    \n",
    "    return {\"prec\" : prec, \"rec\" : rec, \"acc\" : acc, \"f1\" : f1, \"TP\" : TP, \"TN\" : TN, \"FP\" : FP, \"FN\" : FN}\n",
    "    \n",
    "e=ddf2.apply(calc, axis=0)\n",
    "e2=pd.DataFrame(list(e.values))\n",
    "\n",
    "print(\"measure results for each g-value\")\n",
    "e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1.columns = [\"1-\"+c for c in e1.columns]\n",
    "e2.columns = [\"2-\"+c for c in e2.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_2 = pd.concat([e1,e2],axis=1)\n",
    "df_1_2[\"diff-f1\"] = df_1_2[\"2-f1\"] -  df_1_2[\"1-f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
