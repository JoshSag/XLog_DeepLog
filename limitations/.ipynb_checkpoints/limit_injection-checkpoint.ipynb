{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.gmtime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "from _code import DeepLogModel\n",
    "from _code import generator\n",
    "from _code import trie\n",
    "from _code import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 40\n",
    "num_patterns = 20\n",
    "vocabulary = generator.make_vocabulary(vocabulary_size=vocabulary_size)\n",
    "patterns = generator.generate_patterns(num_patterns=num_patterns, vocabulary=vocabulary, min_pattern_size=3, max_pattern_size=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie_g = trie.calc_g_value(patterns)\n",
    "trie_h = trie.calc_h_value(patterns)\n",
    "print(\"trie-g:\", trie_g)\n",
    "print(\"trie-h:\", trie_h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, marks_train = generator.generate_text(patterns, text_size=50000, anomaly_ratio=0.00, vocabulary=vocabulary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_log_model = DeepLogModel.DeepLogModel(h=trie_h+1, n=vocabulary_size, vocabulary=vocabulary)\n",
    "deep_log_model.build(num_lstm_layers=2, lstm_size=50)\n",
    "deep_log_model.fit(text_train,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_legit = generator.generate_tests(patterns, vocabulary, n=200, text_size = 4, anomaly_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = time.time()\n",
    "entries = list()\n",
    "for k, (text_test, text_marks, anomaly) in tests_legit.items():\n",
    "    for g in range(0, vocabulary_size+1):\n",
    "        res = deep_log_model.monitor_session(text_test, text_marks, g=g)\n",
    "        entry = (k,g,res)\n",
    "        entries.append(entry)\n",
    "e = time.time()\n",
    "print(\"time:\", round(e-b,3), \"seconds\")\n",
    "# entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(entries, columns = [\"i\",\"g\",\"status\"])\n",
    "ddf = df.pivot_table(index=\"i\", columns = \"g\", values = \"status\", aggfunc = \"sum\")\n",
    "def calc(s):\n",
    "    c = dict(collections.Counter(s))\n",
    "    TP = c.get(\"TP\", 0)\n",
    "    TN = c.get(\"TN\", 0)\n",
    "    FP = c.get(\"FP\", 0)\n",
    "    FN = c.get(\"FN\", 0)\n",
    "    eps = 1e-9\n",
    "    \n",
    "    prec = TP / (TP + FP + eps)\n",
    "    rec = TP / (TP + FN + eps)\n",
    "    acc = (TP + TN) / (TP + TN + FP + FN + eps)\n",
    "    f1 = 2*(prec*rec)/(prec+rec+eps)\n",
    "    \n",
    "    return {\"prec\" : prec, \"rec\" : rec, \"acc\" : acc, \"f1\" : f1, \"TP\" : TP, \"TN\" : TN, \"FP\" : FP, \"FN\" : FN}\n",
    "    \n",
    "e=ddf.apply(calc, axis=0)\n",
    "e1=pd.DataFrame(list(e.values))\n",
    "\n",
    "print(\"measure results for each g-value\")\n",
    "e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_g = e1[\"f1\"].argmax()\n",
    "print(\"empirical best g:\", best_g)\n",
    "print(\"trie g:\", trie_g)\n",
    "e1.loc[[best_g]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## README\n",
    "1. First we trained the network and knows the best g-value  \n",
    "2. We inject random letters that each of them is within top-g  \n",
    "    2.1. We generate 2 legitimate workflows  \n",
    "    2.2. We inject <15> consecuent letters, each of them within top-g  \n",
    "    2.3. We try to finish with more legitimate workflows  \n",
    "        2.3.1 Until we can inject legitimate workflow without being detected, we continue to inject random letters within top-g  \n",
    "3. We got a text with at least <15> close-to-random letters inside it, and the network didn't alert on it.\n",
    "4. That is an injection attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, marks = generator.generate_text(patterns, text_size=2, anomaly_ratio=0.00, vocabulary=vocabulary) \n",
    "def choose_next(topg_letters, injection_method):\n",
    "    if injection_method == \"random\":\n",
    "        return np.random.choice(list(topg_letters))\n",
    "    else:\n",
    "        raise ValueErorr()\n",
    "\n",
    "        \n",
    "def inject(text, n, injection_method):\n",
    "    text_ = text + [text[-1]] # placeholder\n",
    "    if n == 0:\n",
    "        return text\n",
    "    marks = [1]*len(text_)\n",
    "    df_pred, df_marks = deep_log_model.get_df_pred(text_, marks)\n",
    "    topg_letters = df_pred.iloc[-1].sort_values()[-(best_g):].index\n",
    "    next_letter = choose_next(topg_letters, injection_method = injection_method)\n",
    "    text = text + [next_letter]\n",
    "    return inject(text, n-1,injection_method)\n",
    "\n",
    "before = deep_log_model.monitor_session(text, marks, best_g)\n",
    "print(len(text), before)\n",
    "assert before == \"TN\"\n",
    "print(text, marks)\n",
    "\n",
    "text = inject(text, 15, injection_method = \"random\")\n",
    "marks = [0]*len(text) # there is an anomaly here\n",
    "after1 = deep_log_model.monitor_session(text, marks, best_g)\n",
    "assert after1 == \"FN\" # no alert for our injection so far\n",
    "print(len(text), after1)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# now we want to go back to safety and complete our injection with normal WFs without triggering an alert\n",
    "\n",
    "def inject2(text, patterns):\n",
    "    for p in patterns:\n",
    "        text_ = text + list(p)\n",
    "        marks_ = [0]*len(text_) \n",
    "        res = deep_log_model.monitor_session(text_, marks_, g=best_g)\n",
    "        if res == \"FN\":\n",
    "            text = text_\n",
    "            marks = marks_\n",
    "            success = True\n",
    "            return text, marks, success\n",
    "    \n",
    "    text = inject(text, 1, injection_method=random)\n",
    "    marks = [0]*len(text)\n",
    "    success = False\n",
    "    \n",
    "    return text, marks, success\n",
    "    \n",
    "\n",
    "def inject2_aux(text, n, patterns):\n",
    "    for _ in range(n):\n",
    "        text, marks, success = inject2(text, patterns)\n",
    "        if success:\n",
    "            return text, success\n",
    "    \n",
    "    return None, False\n",
    "\n",
    "def add_workflows(text, patterns, n):\n",
    "    text_add, marks_add = generator.generate_text(patterns, text_size=n, anomaly_ratio=0.00, vocabulary=vocabulary)\n",
    "    text = text + text_add\n",
    "    return text\n",
    "    \n",
    "    \n",
    "text, success = inject2_aux(text, 10, patterns)\n",
    "assert success\n",
    "text = add_workflows(text, patterns, 3)\n",
    "\n",
    "marks = [0]*len(text) # there was an anomaly here\n",
    "after2 = deep_log_model.monitor_session(text, marks, best_g)\n",
    "assert after2 == \"FN\" # no alert for our injection so far\n",
    "print(len(text), after2)\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
