{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.gmtime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools, collections\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from _code import DeepLogModel\n",
    "from _code import generator\n",
    "from _code import seed\n",
    "from _code import trie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameters\n",
    "_seed={0[seed]}\n",
    "subdir = \"{0[subdir]}\"\n",
    "vocabulary_size = {0[vocabulary_size]}\n",
    "num_patterns = {0[num_patterns]}\n",
    "num_new_patterns = {0[num_new_patterns]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed.seed(_seed)\n",
    "subdir = subdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = vocabulary_size\n",
    "num_patterns = num_patterns\n",
    "vocabulary = generator.make_vocabulary(vocabulary_size=vocabulary_size)\n",
    "patterns = generator.generate_patterns(num_patterns=num_patterns, vocabulary=vocabulary, min_pattern_size=3, max_pattern_size=7)\n",
    "trie_g = trie.calc_g_value(patterns)\n",
    "trie_h = trie.calc_h_value(patterns)\n",
    "print(\"trie-g:\", trie_g)\n",
    "print(\"trie-h:\", trie_h)\n",
    "text_train, marks_train = generator.generate_text(patterns, text_size=50000, anomaly_ratio=0.00, vocabulary=vocabulary) \n",
    "tests1 = generator.generate_tests(patterns, vocabulary, n=700, text_size = 4, anomaly_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "\n",
    "def write_inputs1(subdir, vocabulary_size, vocabulary, patterns, text_train, marks_train, tests):\n",
    "    dir_= os.path.join(\"..\\\\inputs\", subdir)\n",
    "    os.makedirs(dir_, exist_ok=True)\n",
    "    j1={\n",
    "        \"vocabulary_size\" : vocabulary_size,\n",
    "        \"vocabulary\" : vocabulary,\n",
    "        \"workflows\" : patterns\n",
    "    }\n",
    "    json.dump(j1, open(os.path.join(dir_, \"v-wf.json\"), \"w\"))\n",
    "\n",
    "    j2 = {\"text_train\" : text_train, \"marks_train\" : marks_train}\n",
    "    json.dump(j2, open(os.path.join(dir_, \"train.json\"), \"w\"))\n",
    "\n",
    "    j3 = {\"tests\" : tests}\n",
    "    json.dump(j3, open(os.path.join(dir_, \"tests1.json\"), \"w\"))\n",
    "\n",
    "def read_inputs1(subdir):\n",
    "    dir_ = os.path.join(\"..\\\\inputs\", subdir)\n",
    "    j1 = json.load(open(os.path.join(dir_, \"v-wf.json\")))\n",
    "    j2 = json.load(open(os.path.join(dir_, \"train.json\")))\n",
    "    j3 = json.load(open(os.path.join(dir_, \"tests1.json\")))\n",
    "    \n",
    "    vocabulary_size = j1[\"vocabulary_size\"]\n",
    "    vocabulary = j1[\"vocabulary\"]\n",
    "    patterns = j1[\"workflows\"]\n",
    "    patterns = [tuple(p) for p in patterns]\n",
    "    \n",
    "    text_train = j2[\"text_train\"]\n",
    "    marks_train = j2[\"marks_train\"]\n",
    "    \n",
    "    tests_str_keys = j3[\"tests\"]\n",
    "    tests = dict()\n",
    "    for k,v in tests_str_keys.items():\n",
    "        tests[int(k)] = tuple(v)\n",
    "    \n",
    "    \n",
    "    return vocabulary_size, vocabulary, patterns, text_train, marks_train, tests\n",
    "\n",
    "write_inputs1(subdir, vocabulary_size, vocabulary, patterns, text_train, marks_train, tests1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_vocabulary_size, ret_vocabulary, ret_patterns, ret_text_train, ret_marks_train, ret_tests1 = read_inputs1(subdir)\n",
    "\n",
    "assert ret_vocabulary_size == vocabulary_size\n",
    "assert ret_vocabulary == vocabulary\n",
    "assert ret_patterns == patterns\n",
    "assert ret_text_train == text_train\n",
    "assert ret_marks_train == marks_train\n",
    "assert ret_tests1 == tests1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_log_model = DeepLogModel.DeepLogModel(h=trie_h+1, n=vocabulary_size, vocabulary=vocabulary)\n",
    "deep_log_model.build(num_lstm_layers=2, lstm_size=64)\n",
    "deep_log_model.fit(text_train,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = time.time()\n",
    "entries = list()\n",
    "for k, (text_test, text_marks, anomaly) in tests1.items():\n",
    "    for g in range(0, vocabulary_size+1):\n",
    "        res = deep_log_model.monitor_session(text_test, text_marks, g=g)\n",
    "        entry = (k,g,res)\n",
    "        entries.append(entry)\n",
    "e = time.time()\n",
    "print(\"time:\", round(e-b,3), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(entries, columns = [\"i\",\"g\",\"status\"])\n",
    "ddf1 = df1.pivot_table(index=\"i\", columns = \"g\", values = \"status\", aggfunc = \"sum\")\n",
    "def calc(s):\n",
    "    c = dict(collections.Counter(s))\n",
    "    TP = c.get(\"TP\", 0)\n",
    "    TN = c.get(\"TN\", 0)\n",
    "    FP = c.get(\"FP\", 0)\n",
    "    FN = c.get(\"FN\", 0)\n",
    "    eps = 1e-9\n",
    "    \n",
    "    prec = TP / (TP + FP + eps)\n",
    "    rec = TP / (TP + FN + eps)\n",
    "    acc = (TP + TN) / (TP + TN + FP + FN + eps)\n",
    "    f1 = 2*(prec*rec)/(prec+rec+eps)\n",
    "    \n",
    "    return {\"prec\" : prec, \"rec\" : rec, \"acc\" : acc, \"f1\" : f1, \"TP\" : TP, \"TN\" : TN, \"FP\" : FP, \"FN\" : FN}\n",
    "    \n",
    "e=ddf1.apply(calc, axis=0)\n",
    "e1=pd.DataFrame(list(e.values))\n",
    "\n",
    "print(\"measure results for each g-value\")\n",
    "e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### finding emprical best g\n",
    "display(e1.loc[[e1[\"acc\"].argmax()]])\n",
    "display(e1.loc[[e1[\"f1\"].argmax()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_g = e1[\"f1\"].argmax()\n",
    "print(\"best-g\", best_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## online_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_new_patterns = num_new_patterns\n",
    "new_patterns = generator.generate_patterns(num_patterns=num_new_patterns, vocabulary=vocabulary, min_pattern_size=3, max_pattern_size=7)\n",
    "\n",
    "online_cases = generator.generate_tests(patterns + new_patterns, vocabulary, n=10000, text_size = 4, anomaly_ratio=0.0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_inputs2(subdir, online_cases):\n",
    "    dir_= os.path.join(\"..\\\\inputs\", subdir)\n",
    "    os.makedirs(dir_, exist_ok=True)\n",
    "    \n",
    "    j4 = {\"online_cases\" : online_cases}\n",
    "    json.dump(j4, open(os.path.join(dir_, \"online_cases.json\"), \"w\"))\n",
    "\n",
    "def read_inputs2(subdir):\n",
    "    dir_ = os.path.join(\"..\\\\inputs\", subdir)\n",
    "    \n",
    "    j4 = json.load(open(os.path.join(dir_, \"online_cases.json\")))\n",
    "    online_cases_str_keys = j4[\"online_cases\"]\n",
    "    online_cases = dict()\n",
    "    for k,v in online_cases_str_keys.items():\n",
    "        online_cases[int(k)] = tuple(v)\n",
    "\n",
    "    return online_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_inputs2(subdir, online_cases)\n",
    "ret_online_cases = read_inputs2(subdir)\n",
    "assert ret_online_cases == online_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie_g_new = trie.calc_g_value(patterns + new_patterns)\n",
    "trie_h_new = trie.calc_h_value(patterns + new_patterns)\n",
    "print(\"best-g:\", best_g)\n",
    "print(\"trie-g new: {}. (prev trie-g: {})\".format(trie_g_new, trie_g))\n",
    "print(\"trie-h new: {}. (prev trie-h: {})\".format(trie_h_new, trie_h))\n",
    "best_g_new = max(best_g, trie_g_new)\n",
    "print(\"best-g-new:\", best_g_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feedbacks = 0\n",
    "num_feedbacks_new = 0\n",
    "num_feedbacks_old = 0\n",
    "\n",
    "def contains_new_pattern(text, new_patterns):\n",
    "    new_ps_str = [\"#\".join(p) for p in new_patterns]\n",
    "    text_str = \"#\".join(text)\n",
    "    for new_p_str in new_ps_str:\n",
    "        if new_p_str in text_str:\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "for index, case in online_cases.items():\n",
    "    text, marks, anomaly_exists = case\n",
    "    res = deep_log_model.monitor_session(text, marks, g=best_g)\n",
    "    if res == \"FP\":\n",
    "        deep_log_model.train_feedback(text, marks, g = best_g) # we are using here the old empirical best g. The theoretical g (trie_g_new) might be higher and give at the end worse results.\n",
    "        num_feedbacks += 1\n",
    "        if contains_new_pattern(text, new_patterns):\n",
    "            num_feedbacks_new +=1\n",
    "        else:\n",
    "            num_feedbacks_old +=1 # count only totally \"old\" feedback cases without any new workflow \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"num_feedbacks_new\", num_feedbacks_new)\n",
    "print(\"num_feedbacks_old\", num_feedbacks_old)\n",
    "print(\"num_feedbacks\", num_feedbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests2 = generator.generate_tests(patterns + new_patterns, vocabulary, n=700, text_size = 4, anomaly_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_inputs3(subdir, tests):\n",
    "    dir_= os.path.join(\"..\\\\inputs\", subdir)\n",
    "    os.makedirs(dir_, exist_ok=True)\n",
    "    \n",
    "    j5 = {\"tests\" : tests}\n",
    "    json.dump(j5, open(os.path.join(dir_, \"tests2.json\"), \"w\"))\n",
    "\n",
    "def read_inputs3(subdir):\n",
    "    dir_= os.path.join(\"..\\\\inputs\", subdir)\n",
    "    j5 = json.load(open(os.path.join(dir_, \"tests2.json\")))\n",
    "    \n",
    "    tests_str_keys = j5[\"tests\"]\n",
    "    tests = dict()\n",
    "    for k,v in tests_str_keys.items():\n",
    "        tests[int(k)] = tuple(v)\n",
    "    return tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_inputs3(subdir, tests2)\n",
    "ret_tests2 = read_inputs3(subdir)\n",
    "assert ret_tests2 == tests2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = time.time()\n",
    "entries = list()\n",
    "for k, (text_test, text_marks, anomaly) in tests2.items():\n",
    "    for g in range(best_g, vocabulary_size+1): # adding WF can't cause lower g.\n",
    "        res = deep_log_model.monitor_session(text_test, text_marks, g=g)\n",
    "        entry = (k,g,res)\n",
    "        entries.append(entry)\n",
    "e = time.time()\n",
    "print(\"time:\", round(e-b,3), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(entries, columns = [\"i\",\"g\",\"status\"])\n",
    "ddf2 = df2.pivot_table(index=\"i\", columns = \"g\", values = \"status\", aggfunc = \"sum\")\n",
    "def calc(s):\n",
    "    c = dict(collections.Counter(s))\n",
    "    TP = c.get(\"TP\", 0)\n",
    "    TN = c.get(\"TN\", 0)\n",
    "    FP = c.get(\"FP\", 0)\n",
    "    FN = c.get(\"FN\", 0)\n",
    "    eps = 1e-9\n",
    "    \n",
    "    prec = TP / (TP + FP + eps)\n",
    "    rec = TP / (TP + FN + eps)\n",
    "    acc = (TP + TN) / (TP + TN + FP + FN + eps)\n",
    "    f1 = 2*(prec*rec)/(prec+rec+eps)\n",
    "    \n",
    "    return {\"g\" : s.name, \"prec\" : prec, \"rec\" : rec, \"acc\" : acc, \"f1\" : f1, \"TP\" : TP, \"TN\" : TN, \"FP\" : FP, \"FN\" : FN}\n",
    "    \n",
    "e=ddf2.apply(calc, axis=0)\n",
    "e2=pd.DataFrame(list(e.values))\n",
    "\n",
    "print(\"measure results for each g-value\")\n",
    "e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result2 = e2.loc[[e2[\"f1\"].argmax()]]\n",
    "best_g2 = best_result2[\"g\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3 = e2[e2[\"g\"] == best_g2].copy()\n",
    "e3[\"num_feedbacks_new\"] = num_feedbacks_new\n",
    "e3[\"num_feedbacks_old\"] = num_feedbacks_old\n",
    "e3[\"num_feedbacks\"] = num_feedbacks\n",
    "e3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
